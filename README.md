# BigData_Clean
大数据清洗流程，小于5TB的情况下可以使用python的pandas，大于5TB的情况下使用hadoop、hive、spark

使用Python Pandas处理亿级数据<br/>
http://www.jqhtml.com/12353.html

别老扯什么Hadoop了，你的数据根本不够大<br/>
https://cloud.tencent.com/info/8bb1ff612967581bd9ed91dd0c5ac933.html

Python Pandas、Spark数据清洗<br/>
https://blog.csdn.net/qq_34531825/article/details/52447709<br/>

[推荐型] 大数据框架【spark，hadoop，hive等】数据清洗适用场景介绍、对比及源码实现<br/>
http://www.aboutyun.com/thread-20808-1-1.html

大数据采集、清洗、处理：使用MapReduce进行离线数据分析完整案例<br/>
http://blog.51cto.com/xpleaf/2095836
